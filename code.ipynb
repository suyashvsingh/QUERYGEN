{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "model = \"gpt-4o\"\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UTILS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_sql_query(sql_query):\n",
    "    response = requests.post(\n",
    "        \"http://localhost:3000/execute-query\",\n",
    "        json={\"query\": sql_query},\n",
    "    ).json()\n",
    "    return response\n",
    "\n",
    "\n",
    "def create_initial_sqlquery(context_aware_prompt):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are an AI assistant specialized in rewriting database queries.\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": context_aware_prompt},\n",
    "        ],\n",
    "        temperature=0.3,\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "\n",
    "def close_database():\n",
    "    response = requests.post(\"http://localhost:3000/close-database\").json()\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 1: User Inputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_database():\n",
    "    response = requests.post(\"http://localhost:3000/initialize-database\").json()\n",
    "    if response[\"status\"] == False:\n",
    "        return response[\"details\"]\n",
    "\n",
    "\n",
    "def create_schema(schema):\n",
    "    response = requests.post(\n",
    "        \"http://localhost:3000/create-schema\",\n",
    "        json={\"schema\": schema},\n",
    "    ).json()\n",
    "\n",
    "    return response\n",
    "\n",
    "def get_tables():\n",
    "    sql_query_to_retrieve_tables = \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
    "    sql_query_output = execute_sql_query(sql_query_to_retrieve_tables)[\"output\"]\n",
    "    all_tables = []\n",
    "    for x in sql_query_output:\n",
    "        all_tables.append(x[\"name\"])\n",
    "    return all_tables\n",
    "\n",
    "\n",
    "def get_columns(table_name):\n",
    "    sql_query_to_retrieve_columns = f\"PRAGMA table_info({table_name});\"\n",
    "    sql_query_output = execute_sql_query(sql_query_to_retrieve_columns)[\"output\"]\n",
    "    all_columns = []\n",
    "    for x in sql_query_output:\n",
    "        all_columns.append(x[\"name\"])\n",
    "    return all_columns\n",
    "\n",
    "\n",
    "def get_rows(table_name):\n",
    "    sql_query_to_retrieve_rows = f\"SELECT * FROM {table_name};\"\n",
    "    sql_query_output = execute_sql_query(sql_query_to_retrieve_rows)[\"output\"]\n",
    "    return sql_query_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2: Question Rewriting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_rows(nlq, rows):\n",
    "    # Compute the embeddings for the NLQ and the rows\n",
    "    nlq_embedding = embedding_model.encode(nlq, convert_to_tensor=True)\n",
    "    rows_embeddings = [\n",
    "        embedding_model.encode(str(row), convert_to_tensor=True) for row in rows\n",
    "    ]\n",
    "\n",
    "    # Compute the cosine similarity between the NLQ and the rows\n",
    "    similarity = [\n",
    "        util.pytorch_cos_sim(nlq_embedding, row_embedding)\n",
    "        for row_embedding in rows_embeddings\n",
    "    ]\n",
    "\n",
    "    # Sort the rows based on the similarity\n",
    "    sorted_rows = [row for _, row in sorted(zip(similarity, rows), reverse=True)]\n",
    "    return sorted_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_rewrite(nlq, five_rows, columns):\n",
    "    # Construct the prompt for zero-shot question rewriting\n",
    "    prompt = f\"\"\"\n",
    "    You are an AI assistant tasked with ensuring the given question aligns with the provided database schema and data. Your role is to:\n",
    "\n",
    "    1. Analyze the question for clarity and accuracy.\n",
    "    2. Ensure the question matches the terminology, structure, and relationships (e.g., foreign keys) in the database schema.\n",
    "    3. Rewrite the question if needed to make it unambiguous and aligned with the schema.\n",
    "    4. If the question is already clear and aligned, return it without changes.\n",
    "\n",
    "    ### Instructions:\n",
    "    - Only rewrite the question if necessary for clarity or schema alignment.\n",
    "    - Maintain the intent of the original question.\n",
    "    - Do not modify the schema or sample data.\n",
    "\n",
    "    ### Input Details:\n",
    "    **Database Schema:**\n",
    "    {columns}\n",
    "\n",
    "    **Sample Data:**\n",
    "    {five_rows}\n",
    "\n",
    "    **Original Question:**\n",
    "    {nlq}\n",
    "\n",
    "    ### Output:\n",
    "    - Provide the updated question if rewritten.\n",
    "    - If no changes are needed, return the original question as is.\n",
    "    \"\"\"\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        temperature=0.3,\n",
    "    )\n",
    "    return completion.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3: Context-Aware Prompt Generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_context_aware_prompt(nlq, top_five_rows, columns):\n",
    "    prompt = f\"\"\"\n",
    "    You are tasked with generating a valid SQL query based on the provided question, database schema, and sample data. Follow these strict guidelines:\n",
    "\n",
    "    1. **No LEFT JOIN**: Avoid using the LEFT JOIN keyword.\n",
    "    2. **No Aliases for Aggregate Functions**: Do not assign aliases to aggregate functions.\n",
    "    3. **Simplicity**: Focus on generating the simplest query that satisfies the question.\n",
    "    4. **Output Format**: Do not include additional text, explanations, or formatting like ```sql, code, or markdown```. Always return a valid SQL query ending with a semicolon.\n",
    "\n",
    "    ### Hints:\n",
    "    - Use COUNT(*) instead of using column names in the COUNT function.\n",
    "    - Use OR instead of keywords like IN or BETWEEN for better performance.\n",
    "\n",
    "    ### Input Details:\n",
    "    **Database Schema:**\n",
    "    {columns}\n",
    "\n",
    "    **Sample Data:**\n",
    "    {top_five_rows}\n",
    "\n",
    "    **Question:**\n",
    "    {nlq}\n",
    "\n",
    "    ### Output:\n",
    "    A single valid SQL query that adheres to the above rules.\n",
    "    \"\"\"\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 4: Execution-Guided Refinemen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execution_guided_refinement(context_aware_prompt, nlq, columns):\n",
    "    sql_query = create_initial_sqlquery(context_aware_prompt)\n",
    "    sql_query_output = execute_sql_query(sql_query=sql_query)[\"output\"]\n",
    "\n",
    "    for _ in range(5):\n",
    "        refined_sql_query, refined_sql_query_output = refinement_iteration(\n",
    "            nlq, sql_query, sql_query_output, columns\n",
    "        )\n",
    "        if refined_sql_query.strip() == sql_query.strip() or len(\n",
    "            refined_sql_query_output\n",
    "        ) == len(sql_query_output):\n",
    "            break\n",
    "        sql_query = refined_sql_query\n",
    "        sql_query_output = refined_sql_query_output\n",
    "\n",
    "    return sql_query, sql_query_output\n",
    "\n",
    "\n",
    "def refinement_iteration(nlq, sql_query, sql_query_output, columns):\n",
    "    prompt = f\"\"\"\n",
    "    You are tasked with verifying and correcting an SQL query based on the provided natural language question, its current output, and the database schema. Follow these strict rules:\n",
    "\n",
    "    ### Input:\n",
    "    1. **Natural Language Question**: The original query intent.\n",
    "    2. **SQL Query**: The current SQL query to verify.\n",
    "    3. **Query Output**: The result of executing the SQL query (can be empty if no rows satisfy the query).\n",
    "    4. **Database Schema**: Structure of the database tables.\n",
    "    \n",
    "    ### Output:\n",
    "    - If the query and results are both correct, return the original query without changes.\n",
    "    - Ensure column references are consistent with the schema and tables. Always return a valid SQL query ending with a semicolon.\n",
    "    - Do not include additional text, explanations, or formatting like ```sql, code, or markdown```.\n",
    "\n",
    "    ### Provided Data:\n",
    "    **Database Schema:**\n",
    "    {columns}\n",
    "\n",
    "    **Natural Language Question:**\n",
    "    {nlq}\n",
    "\n",
    "    **SQL Query:**\n",
    "    {sql_query}\n",
    "\n",
    "    **Query Output:**\n",
    "    {sql_query_output}\n",
    "\n",
    "    ### Output:\n",
    "    - A valid SQL query that satisfies the above instructions.\n",
    "    \"\"\"\n",
    "\n",
    "    # Call the LLM to refine the SQL query\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        temperature=0.3,\n",
    "    )\n",
    "\n",
    "    refined_query = completion.choices[0].message.content\n",
    "\n",
    "    # Execute the refined SQL query to get feedback\n",
    "    refined_sql_query_output = execute_sql_query(refined_query)\n",
    "\n",
    "    return refined_query, refined_sql_query_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    with open(\"dev.json\") as f:\n",
    "        dev = json.load(f)\n",
    "\n",
    "    for i in range(0, 100):\n",
    "        database_id = dev[i][\"db_id\"]\n",
    "        nlq = dev[i][\"question\"]\n",
    "        dir = f\"database/{database_id}/\"\n",
    "        for path in os.listdir(dir):\n",
    "            if path.endswith(\".sql\"):\n",
    "                with open(dir + path) as f:\n",
    "                    schema = f.read()\n",
    "                    break\n",
    "\n",
    "        # Initialize the database\n",
    "        initialize_database()\n",
    "\n",
    "        # Create the schema\n",
    "        create_schema(schema)\n",
    "\n",
    "        # Get the table names\n",
    "        tables = get_tables()\n",
    "\n",
    "        # Get the columns and rows for each table\n",
    "        columns = {}\n",
    "        for table in tables:\n",
    "            columns[table] = get_columns(table)\n",
    "        rows = {}\n",
    "        for table in tables:\n",
    "            rows[table] = get_rows(table)\n",
    "\n",
    "        # Sort the rows based on the similarity with the NLQ\n",
    "        sorted_rows = {}\n",
    "        for table in tables:\n",
    "            sorted_rows[table] = sort_rows(nlq, rows[table])\n",
    "\n",
    "        # Rewrite the NLQ based on 5 random rows from each table\n",
    "        five_rows = {}\n",
    "        for table in tables:\n",
    "            five_rows[table] = rows[table][:5]\n",
    "        rewriten_nlq = question_rewrite(nlq=nlq, five_rows=five_rows, columns=columns)\n",
    "\n",
    "        # Get the top 5 similar rows for each table\n",
    "        top_five_rows = {}\n",
    "        for table in tables:\n",
    "            top_five_rows[table] = sorted_rows[table][:5]\n",
    "\n",
    "        # Generate the context-aware prompt\n",
    "        context_aware_prompt = generate_context_aware_prompt(\n",
    "            nlq=rewriten_nlq, top_five_rows=top_five_rows, columns=columns\n",
    "        )\n",
    "\n",
    "        # Execute the execution-guided refinement process\n",
    "        final_sql_query, final_sql_query_output = execution_guided_refinement(\n",
    "            context_aware_prompt=context_aware_prompt, nlq=nlq, columns=columns\n",
    "        )\n",
    "\n",
    "        # Write the final SQL query to a file\n",
    "        final_sql_query = final_sql_query.replace(\"\\n\", \" \")\n",
    "        with open(\"predictions.sql\", \"a\") as f:\n",
    "            f.write(final_sql_query)\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "        # Close the database\n",
    "        close_database()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
